{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5984c69f-bb7d-4bbd-b02f-b72284fa28d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, mean_absolute_percentage_error\n",
    "from sklearn import linear_model\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "pd.options.display.max_columns = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfaf7fef-4333-4009-ac69-9142ad497208",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Data/immo_data.csv\")\n",
    "desc = pd.read_csv(\"Data/immo_data_column_description.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4851f20-f4c7-4ab3-b727-ce537c55157a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_columns(df):\n",
    "    \"\"\" Remove (supposedly) unimportant columns \"\"\"\n",
    "    return df.drop(\n",
    "        [\n",
    "            \"scoutId\",\n",
    "            \"houseNumber\",\n",
    "            \"geo_bln\",\n",
    "            \"geo_krs\",\n",
    "            \"geo_plz\",\n",
    "            \"date\",\n",
    "            \"street\",\n",
    "            \"streetPlain\",\n",
    "            \"description\",\n",
    "            \"facilities\",\n",
    "            \"regio3\",\n",
    "            \"firingTypes\",\n",
    "            \"telekomHybridUploadSpeed\",\n",
    "            \"totalRent\",\n",
    "            \"baseRentRange\",\n",
    "        ],\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "\n",
    "def remove_outliers(df, lower_limit=0.005, upper_limit=0.995):\n",
    "    \"\"\" Removing the (lower and upper) outliers \"\"\"\n",
    "    dfc = df.copy()\n",
    "    columns_with_outliers = [\n",
    "        \"serviceCharge\",\n",
    "        \"yearConstructed\",\n",
    "        \"noParkSpaces\",\n",
    "        \"baseRent\",\n",
    "        \"livingSpace\",\n",
    "        \"noRooms\",\n",
    "        \"floor\",\n",
    "        \"numberOfFloors\",\n",
    "        \"heatingCosts\",\n",
    "        \"lastRefurbish\",\n",
    "    ]\n",
    "    \n",
    "    # For each column we keep: Data that is < (99.5% quantile) and > (0.5% quantile) OR that is NaN (we will deal with this later) \n",
    "    upper_limits = df[columns_with_outliers].quantile(upper_limit)\n",
    "    lower_limits = df[columns_with_outliers].quantile(lower_limit)\n",
    "    \n",
    "    for colname in columns_with_outliers:\n",
    "        col = dfc[colname]\n",
    "        dfc = dfc[\n",
    "            ((col <= upper_limits[colname]) & (col >= lower_limits[colname]))\n",
    "            | col.isna()\n",
    "        ]\n",
    "    return dfc\n",
    "\n",
    "\n",
    "def remove_rows_with_NaN_target(df):\n",
    "    \"\"\" Removing the records without a label \"\"\"\n",
    "    return df[df[\"baseRent\"].isna() == False]\n",
    "\n",
    "\n",
    "def impute_NaNs(df):\n",
    "    \"\"\" Replacing NaNs with mean or most frequent \"\"\"\n",
    "    dfc = df.copy()\n",
    "    categorical_columns = dfc.select_dtypes(exclude=np.number).columns\n",
    "    imp_freq = SimpleImputer(missing_values=np.nan, strategy=\"most_frequent\")\n",
    "    dfc.loc[:, categorical_columns] = imp_freq.fit_transform(dfc[categorical_columns])\n",
    "\n",
    "    numeric_columns = dfc.select_dtypes(include=np.number).columns\n",
    "    imp_mean = SimpleImputer(missing_values=np.nan, strategy=\"mean\")\n",
    "    #dfc.loc[:, numeric_columns] = imp_mean.fit_transform(dfc[numeric_columns])\n",
    "    dfc[numeric_columns] = imp_mean.fit_transform(dfc[numeric_columns])\n",
    "    return dfc\n",
    "\n",
    "\n",
    "def print_evaluation(pipeline_or_model, X_train, X_test, y_train, y_test, y_train_pred, y_test_pred, feature_names):\n",
    "    \"\"\" Output of R2 value, MSE and MAE for training and test set \"\"\"\n",
    "    r2_train = r2_score(y_train, y_train_pred)\n",
    "    mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "    mae_train = mean_absolute_error(y_train, y_train_pred)\n",
    "    mape_train = mean_absolute_percentage_error(y_train, y_train_pred)\n",
    "\n",
    "    r2_test = r2_score(y_test, y_test_pred)\n",
    "    mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "    mae_test = mean_absolute_error(y_test, y_test_pred)\n",
    "    mape_test = mean_absolute_percentage_error(y_test, y_test_pred)\n",
    "    \n",
    "    print(\n",
    "        f\"{pipeline_or_model} Evaluation:\\n\"\n",
    "        f\"{'':6} {'R²':>10} | {'MSE':>14} | {'MAE':>10} | {'MAPE':>10} | {'rows':>8} | {'columns':>8}\\n\"\n",
    "        f\"{'Train':6} {r2_train:10.5f} | {mse_train:14.2f} | {mae_train:10.2f} | {mape_train:10.2f} | {X_train.shape[0]:8} | {X_train.shape[1]:8}\\n\"\n",
    "        f\"{'Test':6} {r2_test:10.5f} | {mse_test:14.2f} | {mae_test:10.2f} | {mape_test:10.2f} | {X_test.shape[0]:8} | {X_test.shape[1]:8}\\n\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "016fed6a-366d-41a2-83bc-e012c697c8c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge(alpha=1, random_state=42) Evaluation:\n",
      "               R² |            MSE |        MAE |       MAPE |     rows |  columns\n",
      "Train     0.84369 |       25629.80 |     104.07 |       0.18 |     7742 |      505\n",
      "Test      0.82320 |       28617.03 |     113.75 |       0.20 |     1936 |      505\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Prepare the data\n",
    "df_reduced = drop_columns(df.sample(10000, random_state=42))\n",
    "#df_reduced = drop_columns(df)\n",
    "df_reduced = remove_outliers(df_reduced)\n",
    "df_reduced = remove_rows_with_NaN_target(df_reduced)\n",
    "df_reduced = impute_NaNs(df_reduced)\n",
    "df_reduced = pd.get_dummies(df_reduced)\n",
    "y = df_reduced.pop(\"baseRent\")\n",
    "\n",
    "# Training-Test-Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_reduced, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Training and Hyperparameter search\n",
    "parameters = {\"alpha\": [1e-3, 1e-1, 1, 10]} #\"max_depth\"=[1,2,3,4,79]\n",
    "m = linear_model.Ridge(random_state=42)\n",
    "gs = GridSearchCV(m, parameters)\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "# Predict with the best model\n",
    "y_train_pred = gs.predict(X_train)\n",
    "y_test_pred = gs.predict(X_test)\n",
    "\n",
    "# Evaluation. The best model is stored under gs.best_estimator_. \n",
    "print_evaluation(gs.best_estimator_, X_train, X_test, y_train, y_test, y_train_pred, y_test_pred, feature_names=df_reduced.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77f4169-c251-4d1f-a557-e23e7a365bb7",
   "metadata": {},
   "source": [
    "### Task 1\n",
    "Train a random forest for the apartment example. Experiment with the parameters ``n_estimators``, ``max_depth`` and ``max_features`` to optimize the performance (either manually or with GridSearchCV --> Caution, computing time!). What do the parameters mean?    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "effcbba4-12dc-4f79-8892-fa446af437ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d765e2e2-dd91-427b-af5e-8036b26f3cb8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Task 2\n",
    "Train a AdaBoost regression model for the apartment example. Experiment with the parameters ``n_estimators``, ``learning_rate`` and ``loss`` to optimize the performance (either manually or with GridSearchCV --> Caution, computing time!). What do the parameters mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f83e0448",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "# Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b573910-1288-44ad-96dd-209e637b7c05",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Task 3\n",
    "Which algorithm is implemented in the following code?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd85234b-1e2a-4fe9-86ea-18a294b4b3aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.9895333333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.stats import mode\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "n_trees = 500\n",
    "accuracy_scores = []\n",
    "\n",
    "Y_pred = np.empty([n_trees, len(X_test)], dtype=np.uint8)\n",
    "\n",
    "for k in range(n_trees):\n",
    "    X_train_, y_train_ = resample(X_train, y_train, replace=True)\n",
    "    \n",
    "    clf = DecisionTreeClassifier(random_state=42)\n",
    "    clf.fit(X_train_, y_train_)\n",
    "    \n",
    "    Y_pred[k] = clf.predict(X_test)\n",
    "    accuracy_scores.append(accuracy_score(y_test, clf.predict(X_test)))\n",
    "\n",
    "y_pred, count = mode(Y_pred, keepdims=True)\n",
    "print(accuracy_score(y_test, y_pred[0]))\n",
    "print(np.mean(accuracy_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c15d25-aac1-4ac8-9af4-f97ed6767741",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
